â™»ï¸ Waste Management and Recycling Prediction Project
ğŸ“‹ Overview
This project builds a machine learning model to predict the Recycling Rate (%) for waste management in Indian cities using the Waste Management and Recycling in India dataset (2019â€“2023). The dataset includes features like Waste Generated (Tons/Day), Population Density, City/District, Waste Type, and Disposal Method. The goal is to optimize waste management and reduce landfill dependency through accurate predictions, served via a Flask web app with a user-friendly interface. ğŸš€
ğŸ¯ Objectives

Predict Recycling Rates: Use regression models to forecast Recycling Rate (%) based on waste management features. ğŸ“ˆ
Enhance Model Performance: Achieve high RÂ² scores (target â‰¥ 0.80) using advanced feature engineering and ensemble methods. ğŸ§ 
Deploy a Web Interface: Provide a Flask-based interface for users to input data and get predictions. ğŸŒ
Ensure Reproducibility: Serialize models and preprocessing artifacts for consistent training and prediction. ğŸ’¾

ğŸ—‚ï¸ Project Structure
â”œâ”€â”€ ğŸ“‚ datasets/
â”‚   â”œâ”€â”€ ğŸ“‚ raw/
â”‚   â”‚   â””â”€â”€ Waste_Management_and_Recycling_India.csv
â”‚   â”œâ”€â”€ ğŸ“‚ processed/
â”‚   â”‚   â”œâ”€â”€ target_encodings.pkl
â”‚   â”‚   â”œâ”€â”€ trained_model.pkl
â”‚   â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â”‚   â”œâ”€â”€ selector.pkl
â”‚   â”‚   â”œâ”€â”€ model_name.pkl
â”‚   â”‚   â””â”€â”€ hybrid_model_results.csv
â”œâ”€â”€ ğŸ“‚ src/
â”‚   â”œâ”€â”€ ğŸ“‚ config/
â”‚   â”‚   â””â”€â”€ config.yaml
â”‚   â”œâ”€â”€ ğŸ“‚ data_processing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ preprocess.py
â”‚   â”œâ”€â”€ ğŸ“‚ pipelines/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ training_pipelines.py
â”‚   â”‚   â”œâ”€â”€ prediction_pipelines.py
â”‚   â”œâ”€â”€ ğŸ“‚ utils/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ helper.py
â”‚   â”œâ”€â”€ ğŸ“‚ logger/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ logs.py
â”œâ”€â”€ ğŸ“‚ static/
â”‚   â””â”€â”€ style.css
â”œâ”€â”€ ğŸ“‚ templates/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ result.html
â”‚   â”œâ”€â”€ error.html
â”œâ”€â”€ ğŸ“‚ logs/
â”‚   â””â”€â”€ pipeline.log
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt

ğŸš€ Getting Started
Prerequisites

Python 3.8+ ğŸ
Virtual environment (recommended)
Dependencies listed in requirements.txt

Installation

Clone the repository:git clone <repository-url>
cd waste-management-prediction


Set up a virtual environment:python -m venv venv
.\venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac


Install dependencies:pip install -r requirements.txt


Place the dataset:
Ensure Waste_Management_and_Recycling_India.csv is in datasets/raw/.



Running the Project

Train the Model:

Run the Flask app and train via the web interface:python app.py


Open http://localhost:5000 and click "Train Model".


Or run the training pipeline standalone:python src/pipelines/training_pipelines.py


Check logs/pipeline.log for training logs and verify artifacts in datasets/processed/:
target_encodings.pkl ğŸ—ï¸
trained_model.pkl ğŸ¤–
scaler.pkl ğŸ“
selector.pkl ğŸ”
model_name.pkl ğŸ·ï¸
hybrid_model_results.csv ğŸ“Š




Make Predictions:

With the Flask app running, go to http://localhost:5000.
Enter values for features (e.g., Waste Generated (Tons/Day), City/District).
Submit to get the predicted Recycling Rate (%). âœ…
Check logs/pipeline.log for prediction logs.



ğŸ”§ Key Components
1. Data Preprocessing (preprocess.py) ğŸ› ï¸

Feature Engineering: Creates 37 features from 9 input columns, including:
Coordinate parsing (Landfill_Lat, Landfill_Long)
Ratios (Waste_Per_Capita, Cost_Efficiency)
Target encoding for categorical columns (City/District, Waste Type, Disposal Method)
City/waste type statistics
Log transformations and polynomial features


Data Augmentation: Uses SMOTE-like techniques and noise addition to increase dataset size (from 850 to ~3400 rows).
Artifacts: Saves target_encodings.pkl, scaler.pkl, and selector.pkl for consistent prediction.

2. Training Pipeline (training_pipelines.py) ğŸ‹ï¸

Models: Trains a Stacking Ensemble (RandomForest, ExtraTrees, GradientBoosting, LightGBM, XGBoost with LinearRegression meta-model) and a Deep XGBoost model.
Feature Selection: Uses SelectKBest with mutual_info_regression to select top features.
Outcome: Selects the best model based on RÂ² (e.g., Stacking Ensemble: 0.9725, Deep XGBoost: ~0.7225).
Artifacts: Saves trained_model.pkl, model_name.pkl, and others.

3. Prediction Pipeline (prediction_pipelines.py) ğŸ”®

Process: Applies the same feature engineering as training, scales with scaler.pkl, selects features with selector.pkl, and predicts using the best model.
Fixes: Ensures identical feature set (37 features) and shape as training by using saved artifacts.

4. Flask Web App (app.py, templates/, static/) ğŸŒ

Interface: Uses Tailwind CSS and Bootstrap for a dark-themed, user-friendly form (index.html).
Endpoints:
/: Form to input features.
/train: Triggers training and saves artifacts.
/predict: Returns predicted Recycling Rate (%) in result.html.


Error Handling: Displays errors in error.html if artifacts are missing.

ğŸ›‘ Challenges and Solutions


Low RÂ² Scores ğŸ“‰

Issue: Initial models had low performance (e.g., -12% RÂ²).
Solution: Implemented advanced feature engineering, data augmentation, and ensemble models, achieving RÂ² up to 0.9725.



ğŸ“Š Outcomes

Model Performance:
Stacking Ensemble: RÂ² = 0.9725, high accuracy for complex patterns.
Deep XGBoost: RÂ² â‰ˆ 0.7225, robust fallback.
Dataset Size: Augmented from 850 to ~3400 rows.
Features Used: 37 engineered features, reduced to top features via SelectKBest.


Artifacts: All required files (target_encodings.pkl, trained_model.pkl, etc.) are saved in datasets/processed/.
Web Interface: Fully functional Flask app with a dark-themed, responsive UI for predictions. ğŸŒŸ
Logs: Detailed logging in logs/pipeline.log for debugging and monitoring. ğŸ“œ

ğŸ”® Future Improvements

Add Confidence Intervals: Display prediction confidence in result.html. ğŸ“ˆ
Feature Importance: Visualize key features in the web interface. ğŸ“Š
More Data: Incorporate external features (e.g., weather, policies) to boost performance. ğŸŒ
Neural Networks: Explore deep learning for complex interactions. ğŸ§ 
CI/CD Integration: Automate model retraining and deployment with MLflow. ğŸš€

ğŸ› Debugging Tips

Check Logs: Review logs/pipeline.log for errors in training or prediction.
Verify Artifacts: Ensure datasets/processed/ contains all .pkl files after training.
Clear Cache: Remove .pyc files to avoid outdated code:del src\*.pyc /s

 ** Special Thanks to Mr.Shubham Chaudhary" for contribution in this project.**


ğŸ“§ Contact
For questions or contributions, reach out via the repository or email(shubham.chaudhary@pw.live). Letâ€™s make waste management smarter! â™»ï¸